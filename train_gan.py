import torch
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from models.gan import Generator, Discriminator
import os

# ========== –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã ==========
batch_size = 64
image_size = 64
nz = 100  # —Ä–∞–∑–º–µ—Ä –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞
ngf = 64  # —Ä–∞–∑–º–µ—Ä —Ñ–∏—á –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
ndf = 64  # —Ä–∞–∑–º–µ—Ä —Ñ–∏—á –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞
num_epochs = 50
lr = 0.0002
beta1 = 0.5

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ========== –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è CelebA ==========
transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.CenterCrop(image_size),
    transforms.ToTensor(),
    transforms.Normalize([0.5] * 3, [0.5] * 3),
])

# ========== –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º ==========
# –£–±–µ–¥–∏—Å—å, —á—Ç–æ —É —Ç–µ–±—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: data/celeba/faces/000001.jpg –∏ —Ç.–¥.
dataset_path = 'data/celeba'
dataset = datasets.ImageFolder(root=dataset_path, transform=transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# ========== –ú–æ–¥–µ–ª–∏ ==========
netG = Generator(nz, ngf, 3).to(device)
netD = Discriminator(3, ndf).to(device)

# ========== –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã ==========
criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))

# ========== –û–±—É—á–µ–Ω–∏–µ ==========
print("üîÅ Starting Training Loop...")
# ...existing code...

for epoch in range(num_epochs):
    for i, (real_images, _) in enumerate(dataloader):
        b_size = real_images.size(0)
        real_images = real_images.to(device)

        # –ú–µ—Ç–∫–∏
        real_label = torch.ones(b_size, device=device)
        fake_label = torch.zeros(b_size, device=device)

        # === –û–±–Ω–æ–≤–ª—è–µ–º –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä ===
        netD.zero_grad()

        # –ü–æ—Ç–µ—Ä–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö
        output = netD(real_images)
        real_label_resized = torch.ones_like(output)  # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç–∫–∏ –∫ —Ä–∞–∑–º–µ—Ä—É –≤—ã—Ö–æ–¥–∞
        loss_real = criterion(output, real_label_resized)

        # –ü–æ—Ç–µ—Ä–∏ –Ω–∞ —Ñ–µ–π–∫–∞—Ö
        noise = torch.randn(b_size, nz, 1, 1, device=device)
        fake_images = netG(noise)
        output = netD(fake_images.detach())
        fake_label_resized = torch.zeros_like(output)  # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç–∫–∏ –∫ —Ä–∞–∑–º–µ—Ä—É –≤—ã—Ö–æ–¥–∞
        loss_fake = criterion(output, fake_label_resized)

        # –°—É–º–º–∞—Ä–Ω–∞—è –ø–æ—Ç–µ—Ä—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞
        loss_D = loss_real + loss_fake
        loss_D.backward()
        optimizerD.step()

        # === –û–±–Ω–æ–≤–ª—è–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä ===
        netG.zero_grad()
        output = netD(fake_images)
        loss_G = criterion(output, real_label_resized)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–∫–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        loss_G.backward()
        optimizerG.step()

    print(f"[{epoch+1}/{num_epochs}] Loss_D: {loss_D.item():.4f}  Loss_G: {loss_G.item():.4f}")

# ...existing code...
# ========== –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä ==========
os.makedirs('output', exist_ok=True)
torch.save(netG.state_dict(), 'output/generator.pth')
print("‚úÖ Training complete. Model saved to output/generator.pth")
